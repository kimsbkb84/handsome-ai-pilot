"""
í•œì„¬ AI íŒŒì¼ëŸ¿ - ì´ë¯¸ì§€ ë²¡í„° ê²€ìƒ‰ ì¡°íšŒ í™”ë©´ (search.py)

- ìì—°ì–´ ê²€ìƒ‰ / íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ ë¶„ë¦¬
- ìœ ì‚¬ë„ ì ìˆ˜ ì‹œê°í™” (Progress bar)
- ì¹´ë“œí˜• ê²°ê³¼ UI, ì •ë ¬ ì˜µì…˜
- ì¶”ì²œÂ·ìµœê·¼ ê²€ìƒ‰ì–´ (session_state)
â€» uploadÂ·vectordb ì €ì¥ ë¡œì§ì€ ë³€ê²½í•˜ì§€ ì•ŠìŒ.
"""

import streamlit as st
import os
import re
from enum import Enum
from typing import Any

from dotenv import load_dotenv  # pyright: ignore[reportMissingImports]
from vectordb import get_vector_db

# -----------------------------------------------------------------------------
# [ì„¤ì •] ìƒìˆ˜ ë° ê¸°ë³¸ê°’ (í•˜ë“œì½”ë”© ìµœì†Œí™”)
# -----------------------------------------------------------------------------

# ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ë²”ìœ„
DEFAULT_TOP_K = 10
MIN_TOP_K = 1
MAX_TOP_K = 20

# ë²¡í„° DB ê±°ë¦¬(distance) â†’ ìœ ì‚¬ë„ í¼ì„¼íŠ¸ ë³€í™˜ìš©
# ChromaëŠ” L2 ê±°ë¦¬ ë°˜í™˜: ì‘ì„ìˆ˜ë¡ ìœ ì‚¬. ì´ ê°’ìœ¼ë¡œ 0~100% ìŠ¤ì¼€ì¼ë§.
SCORE_DISTANCE_MAX = 2.0  # ê±°ë¦¬ >= ì´ ê°’ì´ë©´ 0% ê·¼ì²˜ë¡œ ì²˜ë¦¬
SCORE_DISTANCE_MIN = 0.0  # ê±°ë¦¬ 0 = 100%

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ í‚¤
SK_RECENT_SEARCHES = "search_recent_searches"
SK_LAST_QUERY = "search_last_query"
SK_LAST_RESULTS = "search_last_results"
MAX_RECENT_SEARCHES = 10

# ì¶”ì²œ ê²€ìƒ‰ì–´ (DBì—ì„œ íƒœê·¸ë¥¼ ëª» ê°€ì ¸ì˜¬ ë•Œë§Œ ì‚¬ìš©, í™•ì¥ ê°€ëŠ¥)
FALLBACK_SUGGESTIONS = [
    "ì›í”¼ìŠ¤, ë„¤ì´ë¹„, ì˜¤í”¼ìŠ¤ë£©",
    "ì—¬ë¦„ì— ì…ê¸° ì¢‹ì€ í°ìƒ‰ ì›í”¼ìŠ¤",
    "ë¦°ë„¨, ìºì£¼ì–¼, ë¯¸ë‹ˆë©€",
    "ì½”íŠ¸, íŠ¸ìœ„ë“œ, ì˜¤ë²„ì‚¬ì´ì¦ˆ",
]


class SortOption(str, Enum):
    """ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ ê¸°ì¤€ (ì¶”ê°€ í™•ì¥ ì‹œ ì—¬ê¸°ë§Œ ìˆ˜ì •)."""
    BY_SIMILARITY = "similarity"      # ìœ ì‚¬ë„ ë†’ì€ ìˆœ (ê¸°ë³¸)
    BY_LATEST = "latest"              # ìµœì‹  ì—…ë¡œë“œ ìˆœ (ë©”íƒ€ë°ì´í„°ì— ë‚ ì§œ ìˆì„ ë•Œ)
    BY_TAG_MATCH = "tag_match"        # íƒœê·¸ ì¼ì¹˜ ê°œìˆ˜ ìˆœ


# -----------------------------------------------------------------------------
# [ì´ˆê¸°í™”] í™˜ê²½ë³€ìˆ˜ ë° í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------------------------

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# Streamlit ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤: í˜ì´ì§€ ì„¤ì •ì€ ìµœìƒë‹¨ í•œ ë²ˆë§Œ
st.set_page_config(page_title="ì´ë¯¸ì§€ ê²€ìƒ‰ | í•œì„¬ AI íŒŒì¼ëŸ¿", layout="wide")


# -----------------------------------------------------------------------------
# [ì„¸ì…˜ ìƒíƒœ] ìµœê·¼ ê²€ìƒ‰ì–´ ì´ˆê¸°í™”
# -----------------------------------------------------------------------------

def _init_session_state():
    """ìµœê·¼ ê²€ìƒ‰ì–´ ë“± ê²€ìƒ‰ ê´€ë ¨ session_state ì´ˆê¸°í™”."""
    if SK_RECENT_SEARCHES not in st.session_state:
        st.session_state[SK_RECENT_SEARCHES] = []
    if SK_LAST_QUERY not in st.session_state:
        st.session_state[SK_LAST_QUERY] = ""
    if SK_LAST_RESULTS not in st.session_state:
        st.session_state[SK_LAST_RESULTS] = []


def _push_recent_search(query: str) -> None:
    """ê²€ìƒ‰ ì‹¤í–‰ ì‹œ ìµœê·¼ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¤‘ë³µÂ·ë¹ˆ ë¬¸ìì—´ ì œì™¸, ìµœëŒ€ ê°œìˆ˜ ìœ ì§€)."""
    q = (query or "").strip()
    if not q:
        return
    recent = st.session_state.get(SK_RECENT_SEARCHES, [])
    if q in recent:
        recent.remove(q)
    recent.insert(0, q)
    st.session_state[SK_RECENT_SEARCHES] = recent[:MAX_RECENT_SEARCHES]


_init_session_state()


# -----------------------------------------------------------------------------
# [ìœ í‹¸] ê±°ë¦¬ â†’ ìœ ì‚¬ë„ í¼ì„¼íŠ¸
# -----------------------------------------------------------------------------

def distance_to_confidence_percent(distance: float) -> float:
    """
    ë²¡í„° DBì—ì„œ ë°˜í™˜ëœ ê±°ë¦¬(distance)ë¥¼ 0~100% ìœ ì‚¬ë„ë¡œ ë³€í™˜.
    Chroma L2: ì‘ì„ìˆ˜ë¡ ìœ ì‚¬. SCORE_DISTANCE_MAX ê¸°ì¤€ìœ¼ë¡œ ì„ í˜• ìŠ¤ì¼€ì¼.
    """
    if distance <= SCORE_DISTANCE_MIN:
        return 100.0
    if distance >= SCORE_DISTANCE_MAX:
        return 0.0
    return max(0.0, min(100.0, 100.0 * (1.0 - distance / SCORE_DISTANCE_MAX)))


# -----------------------------------------------------------------------------
# [ë°ì´í„°] DBì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ íƒœê·¸ ëª©ë¡ ì¶”ì¶œ
# -----------------------------------------------------------------------------

def get_available_tags() -> list[str]:
    """
    vectorDB ë©”íƒ€ë°ì´í„°/ë¬¸ì„œì—ì„œ íƒœê·¸ í›„ë³´ë¥¼ ë™ì ìœ¼ë¡œ ì¶”ì¶œ.
    DB ì ‘ê·¼ ì‹¤íŒ¨ ë˜ëŠ” ë¬¸ì„œ ì—†ìœ¼ë©´ FALLBACK_SUGGESTIONS ê¸°ë°˜ íƒœê·¸ í›„ë³´ ë°˜í™˜.
    """
    try:
        db = get_vector_db()
        # LangChain Chroma: _collection.get()ìœ¼ë¡œ ì „ì²´ ë¬¸ì„œ/ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        coll = getattr(db, "_collection", None)
        if coll is None:
            return _tags_from_fallback()
        raw = coll.get(include=["documents", "metadatas"])
        documents = raw.get("documents") or []
        tags_set = set()
        for doc_list in documents:
            for doc in doc_list if isinstance(doc_list, list) else [doc_list]:
                if not isinstance(doc, str):
                    continue
                # ì €ì¥ í˜•ì‹: "ì›í”¼ìŠ¤, ë„¤ì´ë¹„, ë¡±ê¸°ì¥, ë¦°ë„¨, ..."
                for part in re.split(r"[,ï¼Œ\s]+", doc.strip()):
                    t = part.strip()
                    if len(t) >= 1 and len(t) <= 30:
                        tags_set.add(t)
        return sorted(tags_set) if tags_set else _tags_from_fallback()
    except Exception:
        return _tags_from_fallback()


def _tags_from_fallback() -> list[str]:
    """FALLBACK_SUGGESTIONSì—ì„œ ë‹¨ì¼ íƒœê·¸/í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•´ ë°˜í™˜ (ì¤‘ë³µ ì œê±°)."""
    tags_set = set()
    for s in FALLBACK_SUGGESTIONS:
        for part in re.split(r"[,ï¼Œ\s]+", s.strip()):
            t = part.strip()
            if t:
                tags_set.add(t)
    return sorted(tags_set)


# -----------------------------------------------------------------------------
# [ê²€ìƒ‰] ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (ì ìˆ˜ í¬í•¨)
# -----------------------------------------------------------------------------

def run_vector_search(query_text: str, k: int) -> list[tuple[Any, float]]:
    """
    ìì—°ì–´ ë˜ëŠ” íƒœê·¸ ì¡°í•© ë¬¸ìì—´ë¡œ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰.
    ë°˜í™˜: [(Document, distance), ...] (distanceëŠ” ì‘ì„ìˆ˜ë¡ ìœ ì‚¬).
    """
    if not (query_text or query_text.strip()):
        return []
    try:
        db = get_vector_db()
        # similarity_search_with_score: (Document, distance) ë¦¬ìŠ¤íŠ¸
        pairs = db.similarity_search_with_score(query_text.strip(), k=k)
        return list(pairs)
    except Exception:
        return []


# -----------------------------------------------------------------------------
# [ì •ë ¬] ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ (SortOption enum ì‚¬ìš©)
# -----------------------------------------------------------------------------

def sort_search_results(
    pairs: list[tuple[Any, float]],
    option: SortOption,
) -> list[tuple[Any, float]]:
    """
    (Document, distance) ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ íƒí•œ ì •ë ¬ ê¸°ì¤€ì— ë”°ë¼ ì •ë ¬.
    - BY_SIMILARITY: ê±°ë¦¬ ì˜¤ë¦„ì°¨ìˆœ (ì´ë¯¸ DB ê¸°ë³¸ ìˆœì„œì¼ ìˆ˜ ìˆìŒ)
    - BY_LATEST: ë©”íƒ€ë°ì´í„° uploaded_at ë‚´ë¦¼ì°¨ìˆœ (í‚¤ ì—†ìœ¼ë©´ ìœ ì‚¬ë„ ìœ ì§€)
    - BY_TAG_MATCH: page_content(íƒœê·¸ ë¬¸ìì—´) ê¸¸ì´ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ëŒ€ë¦¬ (ì¼ì¹˜ ê°œìˆ˜ ê·¼ì‚¬)
    """
    if not pairs:
        return pairs

    if option == SortOption.BY_SIMILARITY:
        return sorted(pairs, key=lambda x: x[1])

    if option == SortOption.BY_LATEST:
        def key_latest(item):
            doc, dist = item
            meta = doc.metadata or {}
            # ì—…ë¡œë“œ ë‚ ì§œ ë©”íƒ€ë°ì´í„° í™•ì¥ ì‹œ ì—¬ê¸°ë§Œ ìˆ˜ì •
            uploaded = meta.get("uploaded_at") or meta.get("created_at") or ""
            return (uploaded, -item[1])  # ë‚ ì§œ ì—†ìœ¼ë©´ ìœ ì‚¬ë„ë¡œ 2ì°¨ ì •ë ¬
        return sorted(pairs, key=key_latest, reverse=True)

    if option == SortOption.BY_TAG_MATCH:
        # íƒœê·¸ ì¼ì¹˜ ê°œìˆ˜ ëŒ€ì‹  ë¬¸ì„œ íƒœê·¸ ê°œìˆ˜(ê¸¸ì´)ë¡œ ì •ë ¬ (í™•ì¥ ì‹œ ì¿¼ë¦¬ íƒœê·¸ì™€ ë§¤ì¹­ ê°œìˆ˜ë¡œ êµì²´ ê°€ëŠ¥)
        def key_tag_match(item):
            doc, dist = item
            content = (doc.page_content or "").strip()
            n = len([x for x in re.split(r"[,ï¼Œ\s]+", content) if x.strip()])
            return (n, -dist)
        return sorted(pairs, key=key_tag_match, reverse=True)

    return pairs


# -----------------------------------------------------------------------------
# [UI ì»´í¬ë„ŒíŠ¸] ê²°ê³¼ ì¹´ë“œ í•œ ê°œ (ì¬ì‚¬ìš©)
# -----------------------------------------------------------------------------

def render_result_card(
    doc: Any,
    rank: int,
    confidence_percent: float,
) -> None:
    """
    ê²€ìƒ‰ ê²°ê³¼ í•œ ê±´ì„ ì¹´ë“œ í˜•íƒœë¡œ ë Œë”ë§.
    - ìˆœìœ„, ìœ ì‚¬ë„(Progress bar), ë©”íƒ€: source, image_type, íƒœê·¸(chip), ì¹´í…Œê³ ë¦¬/ë‚ ì§œ/ì‹œì¦Œ/ë¸Œëœë“œ(ì˜µì…˜).
    - ì´ë¯¸ì§€ URL/ê²½ë¡œëŠ” í˜„ì¬ DBì— ì—†ìœ¼ë¯€ë¡œ í”Œë ˆì´ìŠ¤í™€ë”; ì¶”í›„ ë©”íƒ€ë°ì´í„° í™•ì¥ ì‹œ ì—°ë™.
    """
    meta = doc.metadata or {}
    source = meta.get("source", "(íŒŒì¼ëª… ì—†ìŒ)")
    image_type = meta.get("image_type", "")
    # ì—…ë¡œë“œ ë‚ ì§œÂ·ì¹´í…Œê³ ë¦¬Â·ì‹œì¦ŒÂ·ë¸Œëœë“œ: uploadì—ì„œ ì €ì¥ ì‹œ ì¶”ê°€ ê°€ëŠ¥í•˜ë„ë¡ í‚¤ë§Œ ì‚¬ìš©
    uploaded_at = meta.get("uploaded_at") or "â€”"
    category = meta.get("category") or meta.get("image_type") or "â€”"
    season = meta.get("season") or "â€”"
    brand = meta.get("brand") or "â€”"

    tags_text = (doc.page_content or "").strip()
    tag_list = [t.strip() for t in re.split(r"[,ï¼Œ]+", tags_text) if t.strip()]

    with st.container():
        st.markdown(f"**{rank}. {source}**")
        # ìœ ì‚¬ë„ Progress bar
        st.caption(f"ìœ ì‚¬ë„ **{confidence_percent:.0f}%**")
        st.progress(confidence_percent / 100.0)
        # íƒœê·¸ ì¹© (ê°€ë¡œ ë°°ì¹˜, ìµœëŒ€ 8ê°œ)
        if tag_list:
            show_tags = tag_list[:8]
            chip_cols = st.columns(len(show_tags))
            for idx, tag in enumerate(show_tags):
                with chip_cols[idx]:
                    st.markdown(f"`{tag}`")
        else:
            st.caption("íƒœê·¸ ì—†ìŒ")
        # ë©”íƒ€ ì •ë³´ í•œ ì¤„
        st.caption(f"ì¹´í…Œê³ ë¦¬: {category} Â· ì—…ë¡œë“œ: {uploaded_at} Â· ì‹œì¦Œ: {season} Â· ë¸Œëœë“œ: {brand}")
        st.markdown("---")


# -----------------------------------------------------------------------------
# [UI] ì¶”ì²œ ê²€ìƒ‰ì–´ / ìµœê·¼ ê²€ìƒ‰ì–´ ë¸”ë¡
# -----------------------------------------------------------------------------

def render_suggestions_and_recent():
    """
    ì…ë ¥ì°½ í•˜ë‹¨ì— ì¶”ì²œ ê²€ìƒ‰ì–´ + ìµœê·¼ ê²€ìƒ‰ì–´ ë…¸ì¶œ.
    ì¶”ì²œ: get_available_tags() ë˜ëŠ” FALLBACK ê¸°ë°˜; ìµœê·¼: session_state.
    """
    st.caption("ğŸ’¡ ì¶”ì²œ ê²€ìƒ‰ì–´")
    suggestions = get_available_tags()
    if suggestions:
        # íƒœê·¸ê°€ ë§ìœ¼ë©´ ìƒìœ„ Nê°œë§Œ (ìŠ¬ë¼ì´ìŠ¤ë¡œ í™•ì¥ ê°€ëŠ¥)
        display_tags = suggestions[:12]
        for i in range(0, len(display_tags), 4):
            row = st.columns(4)
            for j, col in enumerate(row):
                idx = i + j
                if idx < len(display_tags):
                    with col:
                        if st.button(
                            display_tags[idx],
                            key=f"suggest_{idx}_{display_tags[idx][:20]}",
                            use_container_width=True,
                        ):
                            st.session_state[SK_LAST_QUERY] = display_tags[idx]
                            st.rerun()
    st.caption("ğŸ•’ ìµœê·¼ ê²€ìƒ‰ì–´")
    recent = st.session_state.get(SK_RECENT_SEARCHES, [])
    if recent:
        for i, q in enumerate(recent[:5]):
            if st.button(q, key=f"recent_{i}_{hash(q) % 10**6}", use_container_width=True):
                st.session_state[SK_LAST_QUERY] = q
                st.rerun()
    else:
        st.caption("_ì•„ì§ ìµœê·¼ ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤._")


# -----------------------------------------------------------------------------
# [ë©”ì¸] ê²€ìƒ‰ ë°©ì‹ ë¶„ë¦¬: ìì—°ì–´ / íƒœê·¸ ê¸°ë°˜
# -----------------------------------------------------------------------------

st.title("ğŸ” íŒ¨ì…˜ ì´ë¯¸ì§€ íƒœê·¸ ê²€ìƒ‰ (Pilot)")
st.caption("ìì—°ì–´ ë˜ëŠ” íƒœê·¸ë¡œ ì €ì¥ëœ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

# ê²€ìƒ‰ ë°©ì‹ íƒ­
tab_natural, tab_tags = st.tabs(["ğŸ” ìì—°ì–´ ê²€ìƒ‰", "ğŸ· íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰"])

# ----- ìì—°ì–´ ê²€ìƒ‰ -----
with tab_natural:
    st.caption("ì˜ˆ: \"ì—¬ë¦„ì— ì…ê¸° ì¢‹ì€ í°ìƒ‰ ì›í”¼ìŠ¤\"")
    natural_query = st.text_input(
        "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        value=st.session_state.get(SK_LAST_QUERY, ""),
        placeholder="ì˜ˆ: ì—¬ë¦„ì— ì…ê¸° ì¢‹ì€ í°ìƒ‰ ì›í”¼ìŠ¤",
        key="natural_search_input",
    )
    render_suggestions_and_recent()
    btn_natural = st.button("ğŸ” ìì—°ì–´ ê²€ìƒ‰", type="primary", key="btn_natural")

# ----- íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ -----
with tab_tags:
    st.caption("íƒœê·¸ë¥¼ ì„ íƒí•˜ë©´ ì¡°í•©í•´ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    available_tags = get_available_tags()
    selected_tags = st.multiselect(
        "íƒœê·¸ ì„ íƒ (ë³µìˆ˜ ê°€ëŠ¥)",
        options=available_tags,
        default=[],
        key="tag_multiselect",
    )
    tag_query = ", ".join(selected_tags) if selected_tags else ""
    btn_tag = st.button("ğŸ· íƒœê·¸ë¡œ ê²€ìƒ‰", type="primary", key="btn_tag")

# ê³µí†µ: ê²°ê³¼ ê°œìˆ˜, ì •ë ¬ ì˜µì…˜
col1, col2 = st.columns([1, 2])
with col1:
    top_k = st.slider("ê°€ì ¸ì˜¬ ê²°ê³¼ ê°œìˆ˜", min_value=MIN_TOP_K, max_value=MAX_TOP_K, value=DEFAULT_TOP_K)
with col2:
    sort_option = st.selectbox(
        "ì •ë ¬",
        options=[SortOption.BY_SIMILARITY, SortOption.BY_LATEST, SortOption.BY_TAG_MATCH],
        format_func=lambda x: {
            SortOption.BY_SIMILARITY: "ğŸ”¥ ìœ ì‚¬ë„ ë†’ì€ ìˆœ",
            SortOption.BY_LATEST: "ğŸ•’ ìµœì‹  ì—…ë¡œë“œ ìˆœ",
            SortOption.BY_TAG_MATCH: "ğŸ· íƒœê·¸ ì¼ì¹˜ ê°œìˆ˜ ìˆœ",
        }[x],
        index=0,
        key="sort_option",
    )

# ê²€ìƒ‰ ì‹¤í–‰: ì–´ëŠ íƒ­ì—ì„œ ë²„íŠ¼ì„ ëˆŒë €ëŠ”ì§€ì— ë”°ë¼ ì‚¬ìš©í•  ì¿¼ë¦¬ ê²°ì •
search_triggered = False
active_query = ""
if btn_natural and (natural_query or "").strip():
    active_query = natural_query.strip()
    search_triggered = True
elif btn_tag and tag_query:
    active_query = tag_query
    search_triggered = True

# ----- ê²€ìƒ‰ ì‹¤í–‰ ë° ê²°ê³¼ ë Œë”ë§ -----
if search_triggered and active_query:
    _push_recent_search(active_query)
    st.session_state[SK_LAST_QUERY] = active_query

    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        try:
            pairs = run_vector_search(active_query, k=top_k)
            pairs = sort_search_results(pairs, sort_option)

            st.divider()
            st.subheader("ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼")

            if not pairs:
                st.info("ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"ì´ **{len(pairs)}ê±´** ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                for i, (doc, distance) in enumerate(pairs, 1):
                    confidence = distance_to_confidence_percent(distance)
                    render_result_card(doc, i, confidence)
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
